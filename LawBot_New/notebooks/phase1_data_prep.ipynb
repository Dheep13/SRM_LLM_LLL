{"cells":[{"cell_type":"markdown","metadata":{"id":"VV4WiTV5KuP9"},"source":[]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3550,"status":"ok","timestamp":1761617697567,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"oms87dnUK3Qm","outputId":"d757b3ab-65c7-4654-a1d8-513e09312905"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","base_dir = '/content/drive/MyDrive/LawBot'"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":70,"status":"ok","timestamp":1761617753790,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"},"user_tz":-330},"id":"38rpLXCoKuP-","outputId":"622574a7-f2df-405e-dbf6-f72131dc5282"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setting up directory structure...\n","Using base directory: /content/drive/MyDrive/LawBot\n","\n","Creating directory structure...\n","  ✅ /content/drive/MyDrive/LawBot\n","  ✅ /content/drive/MyDrive/LawBot/datasets\n","  ✅ /content/drive/MyDrive/LawBot/data\n","  ✅ /content/drive/MyDrive/LawBot/data/processed\n","  ✅ /content/drive/MyDrive/LawBot/models\n","  ✅ /content/drive/MyDrive/LawBot/models/adapters\n","  ✅ /content/drive/MyDrive/LawBot/vectorstore\n","  ✅ /content/drive/MyDrive/LawBot/vectorstore/faiss_index\n","\n","Checking for required files:\n","  ✅ constitution_qa.json (1.22 MB)\n","  ✅ crpc_qa.json (2.08 MB)\n","  ✅ ipc_qa.json (0.64 MB)\n","\n","✅ All files present. Ready to proceed!\n"]}],"source":["import os\n","\n","# Setup directory structure\n","print(\"Setting up directory structure...\")\n","\n","# Use the base_dir already defined in cell 1\n","print(\"Using base directory:\", base_dir)\n","\n","# Create all necessary directories\n","dirs_to_create = [\n","    base_dir,\n","    f'{base_dir}/datasets',\n","    f'{base_dir}/data',\n","    f'{base_dir}/data/processed',\n","    f'{base_dir}/models',\n","    f'{base_dir}/models/adapters',\n","    f'{base_dir}/vectorstore',\n","    f'{base_dir}/vectorstore/faiss_index'\n","]\n","\n","print(\"\\nCreating directory structure...\")\n","for dir_path in dirs_to_create:\n","    os.makedirs(dir_path, exist_ok=True)\n","    print(f\"  ✅ {dir_path}\")\n","\n","datasets_path = f'{base_dir}/datasets'\n","\n","# Verify required files exist\n","required_files = ['constitution_qa.json', 'crpc_qa.json', 'ipc_qa.json']\n","print(\"\\nChecking for required files:\")\n","all_present = True\n","for file in required_files:\n","    file_path = f'{datasets_path}/{file}'\n","    if os.path.exists(file_path):\n","        size = os.path.getsize(file_path) / (1024*1024)  # Size in MB\n","        print(f\"  ✅ {file} ({size:.2f} MB)\")\n","    else:\n","        print(f\"  ❌ {file} - MISSING!\")\n","        all_present = False\n","\n","if not all_present:\n","    print(f\"\\n❌ Some files are missing. Please upload them to: {datasets_path}/\")\n","else:\n","    print(f\"\\n✅ All files present. Ready to proceed!\")\n"]},{"cell_type":"markdown","metadata":{"id":"J6x_3dHVKuQA"},"source":["# Phase 1: Dataset Preparation for LawBot\n","\n","## Objectives:\n","1. Load and merge constitution_qa.json, crpc_qa.json, and ipc_qa.json\n","2. Transform to instruction format: {instruction, output, source}\n","3. Clean and deduplicate data\n","4. Split 80:20 into train/validation sets\n","5. Generate preprocessing report\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"qqJ33-aDKuQB","executionInfo":{"status":"ok","timestamp":1761617411576,"user_tz":-330,"elapsed":1657,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}}},"outputs":[],"source":["import json\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from collections import Counter\n","import re\n"]},{"cell_type":"markdown","metadata":{"id":"r9yZbY_JKuQB"},"source":["## Step 1: Load Datasets\n"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"Xa9N5ssHKuQC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761617714493,"user_tz":-330,"elapsed":2542,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"2592da0c-cb2f-499b-9cd6-aada5c50134d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading datasets from: /content/drive/MyDrive/LawBot/datasets/\n","Constitution Q&A: 4082 pairs\n","CrPC Q&A: 8194 pairs\n","IPC Q&A: 2267 pairs\n"]}],"source":["# Load all three datasets\n","# Path is determined by the setup cell above\n","print(f\"Loading datasets from: {datasets_path}/\")\n","\n","with open(f'{datasets_path}/constitution_qa.json', 'r', encoding='utf-8') as f:\n","    constitution_data = json.load(f)\n","\n","with open(f'{datasets_path}/crpc_qa.json', 'r', encoding='utf-8') as f:\n","    crpc_data = json.load(f)\n","\n","with open(f'{datasets_path}/ipc_qa.json', 'r', encoding='utf-8') as f:\n","    ipc_data = json.load(f)\n","\n","print(f\"Constitution Q&A: {len(constitution_data)} pairs\")\n","print(f\"CrPC Q&A: {len(crpc_data)} pairs\")\n","print(f\"IPC Q&A: {len(ipc_data)} pairs\")\n"]},{"cell_type":"markdown","metadata":{"id":"YZE4KaGAKuQC"},"source":["## Step 2: Transform to Instruction Format\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"1yhvQQoFKuQC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761617718371,"user_tz":-330,"elapsed":36,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"89bd887f-5afc-47b8-de84-115ce11e0c87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Constitution formatted: 4082\n","CrPC formatted: 8194\n","IPC formatted: 2267\n"]}],"source":["def transform_to_instruction_format(data, source_name):\n","    \"\"\"Transform data from {question, answer} to {instruction, output, source}\"\"\"\n","    formatted_data = []\n","    for item in data:\n","        formatted_data.append({\n","            \"instruction\": item[\"question\"],\n","            \"output\": item[\"answer\"],\n","            \"source\": source_name\n","        })\n","    return formatted_data\n","\n","# Transform each dataset\n","constitution_formatted = transform_to_instruction_format(constitution_data, \"Constitution\")\n","crpc_formatted = transform_to_instruction_format(crpc_data, \"CrPC\")\n","ipc_formatted = transform_to_instruction_format(ipc_data, \"IPC\")\n","\n","print(f\"Constitution formatted: {len(constitution_formatted)}\")\n","print(f\"CrPC formatted: {len(crpc_formatted)}\")\n","print(f\"IPC formatted: {len(ipc_formatted)}\")\n"]},{"cell_type":"markdown","metadata":{"id":"Pay-5ARfKuQC"},"source":["## Step 3: Merge Datasets\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"73RCHhniKuQD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761617722786,"user_tz":-330,"elapsed":61,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"f9c97d44-4844-4d8f-c595-7ebe6c24d07d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total combined data: 14543 pairs\n","\n","Sample data:\n","{\n","  \"instruction\": \"What is India according to the Union and its Territory?\",\n","  \"output\": \"India, that is Bharat, shall be a Union of States.\",\n","  \"source\": \"Constitution\"\n","}\n"]}],"source":["# Combine all datasets\n","combined_data = constitution_formatted + crpc_formatted + ipc_formatted\n","print(f\"Total combined data: {len(combined_data)} pairs\")\n","\n","# Display sample\n","print(\"\\nSample data:\")\n","print(json.dumps(combined_data[0], indent=2, ensure_ascii=False))\n"]},{"cell_type":"markdown","metadata":{"id":"AaM0o9U4KuQD"},"source":["## Step 4: Clean and Deduplicate\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"R0w8Ce3LKuQD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761617726371,"user_tz":-330,"elapsed":450,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"9fed35d1-8013-48cb-fc2c-38f9868ab0b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Removed 21 duplicates\n","Clean data: 14522 pairs\n","\n","Data by source:\n","  Constitution: 4074\n","  CrPC: 8181\n","  IPC: 2267\n"]}],"source":["def normalize_text(text):\n","    \"\"\"Normalize text for comparison\"\"\"\n","    text = text.lower().strip()\n","    text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n","    return text\n","\n","def clean_data(data):\n","    \"\"\"Remove duplicates and clean data\"\"\"\n","    seen = set()\n","    cleaned = []\n","    duplicates_removed = 0\n","\n","    for item in data:\n","        # Create a unique key from instruction and output\n","        key = (normalize_text(item[\"instruction\"]), normalize_text(item[\"output\"]))\n","\n","        if key not in seen:\n","            seen.add(key)\n","            cleaned.append(item)\n","        else:\n","            duplicates_removed += 1\n","\n","    print(f\"Removed {duplicates_removed} duplicates\")\n","    print(f\"Clean data: {len(cleaned)} pairs\")\n","\n","    return cleaned\n","\n","cleaned_data = clean_data(combined_data)\n","\n","# Display statistics by source\n","source_counts = Counter([item[\"source\"] for item in cleaned_data])\n","print(\"\\nData by source:\")\n","for source, count in source_counts.items():\n","    print(f\"  {source}: {count}\")\n"]},{"cell_type":"markdown","metadata":{"id":"GPPOaYf5KuQE"},"source":["## Step 5: Train/Validation Split (80:20)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"sLfoQC6aKuQE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761617730386,"user_tz":-330,"elapsed":81,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"d3e29aed-02fa-4a14-b151-9ccb9894d807"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training data: 11617 pairs\n","Validation data: 2905 pairs\n","\n","Training data by source:\n","  Constitution: 3241\n","  CrPC: 6553\n","  IPC: 1823\n","\n","Validation data by source:\n","  IPC: 444\n","  CrPC: 1628\n","  Constitution: 833\n"]}],"source":["# Split into train and validation sets\n","train_data, val_data = train_test_split(\n","    cleaned_data,\n","    test_size=0.2,\n","    random_state=42,\n","    shuffle=True\n",")\n","\n","print(f\"Training data: {len(train_data)} pairs\")\n","print(f\"Validation data: {len(val_data)} pairs\")\n","\n","# Verify split maintains source distribution\n","train_sources = Counter([item[\"source\"] for item in train_data])\n","val_sources = Counter([item[\"source\"] for item in val_data])\n","\n","print(\"\\nTraining data by source:\")\n","for source, count in train_sources.items():\n","    print(f\"  {source}: {count}\")\n","\n","print(\"\\nValidation data by source:\")\n","for source, count in val_sources.items():\n","    print(f\"  {source}: {count}\")\n"]},{"cell_type":"markdown","metadata":{"id":"zr4xoT0eKuQE"},"source":["## Step 6: Save Processed Data\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"RdrGgJx3KuQE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761617734285,"user_tz":-330,"elapsed":516,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"3ca5579b-64f2-4c10-cf73-810b5ab2978e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Saving outputs to: /content/drive/MyDrive/LawBot/data/processed/\n","✅ Saved 14522 items to /content/drive/MyDrive/LawBot/data/processed/lawbot_cleaned.jsonl\n","✅ Saved 11617 items to /content/drive/MyDrive/LawBot/data/processed/train.jsonl\n","✅ Saved 2905 items to /content/drive/MyDrive/LawBot/data/processed/val.jsonl\n"]}],"source":["def save_jsonl(data, filename):\n","    \"\"\"Save data to JSONL format\"\"\"\n","    # Ensure directory exists\n","    os.makedirs(os.path.dirname(filename), exist_ok=True)\n","\n","    # Save file\n","    with open(filename, 'w', encoding='utf-8') as f:\n","        for item in data:\n","            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n","    print(f\"✅ Saved {len(data)} items to {filename}\")\n","\n","# Save all datasets with dynamic paths\n","output_dir = f'{base_dir}/data/processed'\n","print(f\"\\nSaving outputs to: {output_dir}/\")\n","\n","save_jsonl(cleaned_data, f'{output_dir}/lawbot_cleaned.jsonl')\n","save_jsonl(train_data, f'{output_dir}/train.jsonl')\n","save_jsonl(val_data, f'{output_dir}/val.jsonl')\n"]},{"cell_type":"markdown","metadata":{"id":"NRGQpslIKuQF"},"source":["## Step 7: Generate Preprocessing Report\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"3hVHyGgnKuQF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761617737149,"user_tz":-330,"elapsed":150,"user":{"displayName":"Deepan Shanmugam","userId":"10513139089640654961"}},"outputId":"71dd3843-df2e-4af0-c48b-9514f5657cfa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Preprocessing Report:\n","{\n","  \"dataset_statistics\": {\n","    \"total_samples\": 14522,\n","    \"train_samples\": 11617,\n","    \"val_samples\": 2905,\n","    \"train_ratio\": 0.7999586833769453,\n","    \"val_ratio\": 0.2000413166230547\n","  },\n","  \"source_distribution\": {\n","    \"overall\": {\n","      \"Constitution\": 4074,\n","      \"CrPC\": 8181,\n","      \"IPC\": 2267\n","    },\n","    \"train\": {\n","      \"Constitution\": 3241,\n","      \"CrPC\": 6553,\n","      \"IPC\": 1823\n","    },\n","    \"val\": {\n","      \"IPC\": 444,\n","      \"CrPC\": 1628,\n","      \"Constitution\": 833\n","    }\n","  },\n","  \"text_statistics\": {\n","    \"avg_instruction_length\": 100.9557912133315,\n","    \"avg_output_length\": 121.56404076573475,\n","    \"max_instruction_length\": 1025,\n","    \"max_output_length\": 1398\n","  }\n","}\n"]}],"source":["def generate_report(data, train_data, val_data, filename):\n","    \"\"\"Generate preprocessing report\"\"\"\n","    report = {\n","        \"dataset_statistics\": {\n","            \"total_samples\": len(data),\n","            \"train_samples\": len(train_data),\n","            \"val_samples\": len(val_data),\n","            \"train_ratio\": len(train_data) / len(data),\n","            \"val_ratio\": len(val_data) / len(data)\n","        },\n","        \"source_distribution\": {\n","            \"overall\": dict(Counter([item[\"source\"] for item in data])),\n","            \"train\": dict(Counter([item[\"source\"] for item in train_data])),\n","            \"val\": dict(Counter([item[\"source\"] for item in val_data]))\n","        },\n","        \"text_statistics\": {\n","            \"avg_instruction_length\": sum(len(item[\"instruction\"]) for item in data) / len(data),\n","            \"avg_output_length\": sum(len(item[\"output\"]) for item in data) / len(data),\n","            \"max_instruction_length\": max(len(item[\"instruction\"]) for item in data),\n","            \"max_output_length\": max(len(item[\"output\"]) for item in data)\n","        }\n","    }\n","\n","    with open(filename, 'w', encoding='utf-8') as f:\n","        json.dump(report, f, indent=2, ensure_ascii=False)\n","\n","    print(\"Preprocessing Report:\")\n","    print(json.dumps(report, indent=2, ensure_ascii=False))\n","\n","    return report\n","\n","report = generate_report(cleaned_data, train_data, val_data, f'{base_dir}/data/processed/preprocessing_report.json')\n"]},{"cell_type":"markdown","metadata":{"id":"mSG0yzelKuQF"},"source":["## Summary\n","\n","Phase 1 completed successfully! The dataset has been:\n","1. ✅ Loaded from three JSON files\n","2. ✅ Transformed to instruction format\n","3. ✅ Cleaned and deduplicated\n","4. ✅ Split into train/validation sets (80:20)\n","5. ✅ Saved as JSONL files\n","6. ✅ Preprocessing report generated\n","\n","**Deliverables:**\n","- `data/processed/lawbot_cleaned.jsonl` - Complete cleaned dataset\n","- `data/processed/train.jsonl` - Training set\n","- `data/processed/val.jsonl` - Validation set\n","- `data/processed/preprocessing_report.json` - Statistics report\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}